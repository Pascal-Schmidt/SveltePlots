library(tidyverse)
library(modeltime.gluonts)
library(modeltime)
library(timetk)
library(reticulate)
library(tidymodels)
library(trelliscopejs)
library(data.table)

birds <- readr::read_csv("kaggle_1/data/birds_train.csv")
colnames(birds) <- c("birds", colnames(birds)[-1])  
birds <- birds %>% 
  tidyr::pivot_longer(-birds) %>% 
  dplyr::mutate(date = lubridate::ym(name)) %>% 
  dplyr::select(-name)

bird_names <- birds %>% 
  dplyr::group_by(birds) %>% 
  dplyr::summarise(max = max(value)) %>% 
  dplyr::ungroup() %>% 
  dplyr::filter(max >= 5000) %>% 
  dplyr::pull(birds)

testing_df <- readr::read_csv("/Users/pascal/Downloads/birds_pred.csv") %>% 
  tidyr::separate(ID, c("date", "birds"), sep = ":") %>% 
  dplyr::mutate(date = lubridate::ym(date)) %>% 
  dplyr::rename(value = counts) %>% 
  dplyr::mutate(value = NA) %>% 
  dplyr::filter(birds %in% bird_names)

birds <- birds  %>% 
  dplyr::filter(birds %in% bird_names)

final_df <- dplyr::bind_rows(
  birds,
  testing_df
) %>% 
  dplyr::arrange(date)

df <- data.table::fread("kaggle_1/data/data_dump_2.csv") %>% 
  dplyr::as_tibble() %>% 
  dplyr::mutate(
    date = paste0(year, "-", month) %>% 
      lubridate::ym()
  ) %>% 
  dplyr::group_by(month) %>% 
  dplyr::mutate(
    mean_prec_mm = mean(prec_mm, na.rm = TRUE),
    prec_mm = ifelse(is.na(prec_mm), mean_prec_mm, prec_mm)
  ) %>% 
  dplyr::ungroup() %>% 
  dplyr::select(temp_c:date)

birds_avg <- final_df %>% 
  dplyr::mutate(
    month = lubridate::month(date, label = TRUE)
  ) %>% 
  dplyr::group_by(birds, month) %>% 
  dplyr::summarise(mean_count = mean(value, na.rm = TRUE)) %>% 
  dplyr::ungroup()

final_df <- final_df %>% 
  dplyr::inner_join(
    df, by = "date"
  ) %>% 
  dplyr::mutate(
    month = lubridate::month(date, label = TRUE)
  ) %>% 
  dplyr::inner_join(
    birds_avg, by = c("month", "birds")
  ) %>% 
  dplyr::group_by(birds) %>% 
  # compute fourier series
  timetk::tk_augment_fourier(
    .date_var = date,
    .periods  =  c(3, 6, 12),
    .K = 1
  ) %>% 
  dplyr::ungroup()

# test <- final_df %>% 
#   nest_timeseries(
#     .id_var        = birds,
#     .length_future = 12,
#     .length_actual = 12*3
#   ) %>%
#   split_nested_timeseries(
#     .length_test = 6
#   )

data_prepared_tbl <- final_df %>% 
  dplyr::filter(!is.na(value)) %>% 
  drop_na()

# data_prepared_tbl %>% 
#   dplyr::filter(
#     birds == "American Crow"
#   ) %>% View()

# empty without future data frame augmentation
future_tbl <- final_df %>% 
  dplyr::filter(is.na(value))

# future_tbl %>% 
#   dplyr::filter(
#     birds == "American Crow"
#   ) %>% View()

splits <- data_prepared_tbl %>%
  dplyr::ungroup() %>% 
  timetk::time_series_split(
    date_var = date,
    assess = 6,
    cumulative = TRUE
  )

splits %>% 
  timetk::tk_time_series_cv_plan() %>%
  dplyr::group_by(birds) %>% 
  timetk::plot_time_series_cv_plan(
    .date_var = date,
    .value = value
  )

recipes_base <- recipes::recipe(value ~ ., data = rsample::training(splits))

remove_vars <- c(
  "date_year", "date_half", "date_hour", "date_minute", "date_second", 
  "date_hour12", "date_am.pm", "date_wday.xts", "date_qday", "date_yday",
  "date_mweek", "date_week.iso", "date_week2", "date_week3",
  "date_week4", "date_mday7", "date_year.iso", "date_wday",
  "date_week", "date_day"
)

recipes_glmnet <-  recipes_base %>%
  timetk::step_timeseries_signature(date) %>%
  recipes::step_rm(date) %>%
  recipes::step_rm(!!!syms(remove_vars)) %>%
  recipes::step_normalize(all_numeric(), -all_outcomes()) %>%
  recipes::step_dummy(recipes::all_nominal(), one_hot = TRUE)

model_spec_glmnet <- parsnip::linear_reg(penalty =  tune::tune(), mixture = 1) %>%
  parsnip::set_engine("glmnet")
recipes_glmnet %>% prep() %>% juice()

resamples_kfold <- rsample::vfold_cv(
  rsample::training(splits),
  v = 10
)

grid_spec_glmnet <- lambda_grid <- grid_regular(penalty(), levels = 100)

tune_results_glmnet <- workflows::workflow() %>%
  workflows::add_recipe(recipes_glmnet) %>%
  workflows::add_model(model_spec_glmnet) %>%
  
  tune::tune_grid(
    resamples = resamples_kfold,
    grid      = grid_spec_glmnet,
    metrics   = modeltime::default_forecast_accuracy_metric_set(),
    control   = tune::control_grid(verbose = TRUE, save_pred = TRUE)
  )

readr::write_csv(tune_results_glmnet %>%
                   tune::show_best(metric = "rmse") %>%
                   dplyr::slice(1), "kaggle_1/data/glmnet.csv")

workflow_fit_glmnet <- workflows::workflow() %>%
  workflows::add_recipe(recipes_glmnet) %>%
  workflows::add_model(model_spec_glmnet) %>%
  tune::finalize_workflow(
    tune_results_glmnet %>%
      tune::show_best(metric = "rmse") %>%
      dplyr::slice(1)
  ) %>%
  parsnip::fit(rsample::training(splits))

model_spec_rf <- parsnip::boost_tree(
  mode = "regression",
  mtry = tune::tune(),
  trees = tune::tune(),
  min_n = tune::tune(),
  learn_rate = tune::tune(),
  loss_reduction = tune::tune(),
  tree_depth = tune::tune()
) %>%
  parsnip::set_engine("xgboost")
df_rf <- recipes_glmnet %>% prep() %>% juice()

grid_spec_rf <-
  dials::grid_latin_hypercube(
    dials::mtry(range = c(1, ncol(df_rf) - 1)),
    min_n(),
    trees(),
    tree_depth(),
    learn_rate(range = c(-2.5, -0.5)),
    loss_reduction(),
    size = 20
  )

tune_results_rf_kfold_2 <- workflows::workflow() %>%
  workflows::add_recipe(recipes_glmnet) %>%
  workflows::add_model(model_spec_rf) %>%
  
  tune::tune_grid(
    resamples = resamples_kfold,
    grid      = grid_spec_rf,
    metrics   = modeltime::default_forecast_accuracy_metric_set(),
    control   = tune::control_grid(verbose = TRUE, save_pred = TRUE)
  )

readr::write_csv(tune_results_rf_kfold_2 %>%
                   tune::show_best(metric = "rmse") %>%
                   dplyr::slice(1), "kaggle_1/data/xgboost.csv")

workflow_fit_rf_kfold <- workflows::workflow() %>%
  workflows::add_recipe(recipes_glmnet) %>%
  workflows::add_model(model_spec_rf) %>%
  tune::finalize_workflow(
    tune_results_rf_kfold_2 %>%
      tune::show_best(metric = "rmse") %>%
      dplyr::slice(1)
  ) %>%
  parsnip::fit(rsample::training(splits))

model_tbl_submodels <- modeltime::modeltime_table(
  workflow_fit_rf_kfold,
  workflow_fit_glmnet
)

# get predictions
nbeats_ensemble_df_with_preds <- model_tbl_submodels %>% 
  modeltime::modeltime_forecast(
    new_data    = rsample::testing(splits),
    actual_data = data_prepared_tbl,
    keep_data   = TRUE
  )

x <- nbeats_ensemble_df_with_preds %>% 
  dplyr::select(.key, .index, birds, .value, date, .model_desc) %>% 
  dplyr::group_by(birds) %>% 
  tidyr::pivot_wider(
    names_from = c(".key", ".model_desc"), values_from = .value
  ) %>% 
  dplyr::filter(!is.na(prediction_XGBOOST)) %>% 
  dplyr::mutate(
    rmse_glmnet = yardstick::rmse(., actual_ACTUAL, prediction_GLMNET) %>% list(),
    rmse_xgboost = yardstick::rmse(., actual_ACTUAL, prediction_XGBOOST) %>% list()
  ) %>% 
  dplyr::ungroup() %>% 
  dplyr::select(dplyr::contains("rmse_")) %>% 
  dplyr::distinct()

x$rmse_glmnet[[1]] %>% 
  dplyr::select(birds, .estimate) %>% 
  dplyr::mutate(model = "lasso") %>% 
  dplyr::inner_join(
    x$rmse_xgboost[[1]] %>% 
      dplyr::select(birds, .estimate) %>% 
      dplyr::mutate(model = "xgboost"), by = "birds"
  ) %>% 
  dplyr::mutate(better_model = ifelse(.estimate.x < .estimate.y, "lasso", "xgboost"))
  

nbeats_ensemble_df_with_preds %>%
  dplyr::select(.index, .value, .model_desc, birds) %>%
  dplyr::mutate(
    .value = ifelse(.value < 0, 0, round(.value))
  ) %>% 
  ggplot(aes(x = .index, y = .value, col = .model_desc)) +
  geom_line() +
  theme_bw() +
  theme(legend.position = "bottom") +
  facet_trelliscope(
    ~ birds, nrow = 2, ncol = 4,
    width = 500, scales = "free",
    as_plotly = TRUE
  )

birds <- readr::read_csv("kaggle_1/data/birds_train.csv")
colnames(birds) <- c("birds", colnames(birds)[-1])  
birds <- birds %>% 
  tidyr::pivot_longer(-birds) %>% 
  dplyr::mutate(date = lubridate::ym(name)) %>% 
  dplyr::select(-name)

# specify model specification
recipe_spec_gluon <- recipes::recipe(value ~ birds + date, data = rsample::training(splits)) 

# create model. We are using 4 lookback lengths and also bagging to average models
model_spec_nbeats_ensemble <- modeltime.gluonts::nbeats( 
  id = "birds",
  freq = "M",
  prediction_length = 6,
  lookback_length = c(12, 24, 30),
  loss_function = "MASE",
  bagging_size = 5,
  scale = TRUE,
  num_batches_per_epoch = 16
) %>% 
  parsnip::set_engine("gluonts_nbeats_ensemble")

wflw_fit_nbeats_ensemble <- workflows::workflow() %>% 
  workflows::add_model(model_spec_nbeats_ensemble) %>% 
  workflows::add_recipe(recipe_spec_gluon) %>% 
  parsnip::fit(rsample::training(splits))

model_tbl_submodels <- modeltime::modeltime_table(
  workflow_fit_rf_kfold,
  workflow_fit_glmnet,
  wflw_fit_nbeats_ensemble
)

# get predictions
nbeats_ensemble_df_with_preds <- model_tbl_submodels %>% 
  modeltime::modeltime_forecast(
    new_data    = rsample::testing(splits),
    actual_data = data_prepared_tbl,
    keep_data   = TRUE
  )

x <- nbeats_ensemble_df_with_preds %>% 
  dplyr::select(.key, .index, birds, .value, date, .model_desc) %>% 
  dplyr::group_by(birds) %>% 
  tidyr::pivot_wider(
    names_from = c(".key", ".model_desc"), values_from = .value
  ) %>% 
  dplyr::filter(!is.na(prediction_XGBOOST)) %>% 
  dplyr::mutate(
    rmse_glmnet = yardstick::rmse(., actual_ACTUAL, prediction_GLMNET) %>% list(),
    rmse_xgboost = yardstick::rmse(., actual_ACTUAL, prediction_XGBOOST) %>% list(),
    rmse_nbeats = yardstick::rmse(., actual_ACTUAL, `prediction_NBEATS ENSEMBLE`) %>% list()
  ) %>% 
  dplyr::ungroup() %>% 
  dplyr::select(dplyr::contains("rmse_")) %>% 
  dplyr::distinct()

choose_model <- x$rmse_glmnet[[1]] %>% 
  dplyr::select(birds, .estimate) %>% 
  dplyr::mutate(model = "lasso") %>% 
  dplyr::inner_join(
    x$rmse_xgboost[[1]] %>% 
      dplyr::select(birds, .estimate) %>% 
      dplyr::mutate(model = "xgboost"), by = "birds"
  ) %>% 
  dplyr::inner_join(
    x$rmse_nbeats[[1]] %>% 
      dplyr::select(birds, .estimate) %>% 
      dplyr::mutate(model = "nbeats"), by = "birds"
  ) %>% 
  dplyr::rowwise() %>% 
  dplyr::mutate(
    better_model = dplyr::case_when(
      min(.estimate, .estimate.x, .estimate.y, na.rm = TRUE) == .estimate.x ~ "lasso", 
      min(.estimate, .estimate.x, .estimate.y, na.rm = TRUE) == .estimate.y ~ "xgboost",
      min(.estimate, .estimate.x, .estimate.y, na.rm = TRUE) == .estimate ~ "nbeats"
    )
  ) 

##### train on all data ###
workflow_fit_glmnet <- workflows::workflow() %>%
  workflows::add_recipe(recipes_glmnet) %>%
  workflows::add_model(model_spec_glmnet) %>%
  tune::finalize_workflow(
    tune_results_glmnet %>%
      tune::show_best(metric = "rmse") %>%
      dplyr::slice(1)
  ) %>%
  parsnip::fit(data_prepared_tbl)

workflow_fit_rf_kfold <- workflows::workflow() %>%
  workflows::add_recipe(recipes_glmnet) %>%
  workflows::add_model(model_spec_rf) %>%
  tune::finalize_workflow(
    tune_results_rf_kfold_2 %>%
      tune::show_best(metric = "rmse") %>%
      dplyr::slice(1)
  ) %>%
  parsnip::fit(data_prepared_tbl)

birds <- readr::read_csv("kaggle_1/data/birds_train.csv")
colnames(birds) <- c("birds", colnames(birds)[-1])  
birds <- birds %>% 
  tidyr::pivot_longer(-birds) %>% 
  dplyr::mutate(date = lubridate::ym(name)) %>% 
  dplyr::select(-name)
recipe_spec_gluon <- recipes::recipe(value ~ birds + date, data = birds) 
model_spec_nbeats_ensemble <- modeltime.gluonts::nbeats( 
  id = "birds",
  freq = "M",
  prediction_length = 12,
  lookback_length = c(12, 24, 36),
  loss_function = "MASE",
  bagging_size = 5,
  scale = TRUE,
  num_batches_per_epoch = 16
) %>% 
  parsnip::set_engine("gluonts_nbeats_ensemble")
wflw_fit_nbeats_ensemble <- workflows::workflow() %>% 
  workflows::add_model(model_spec_nbeats_ensemble) %>% 
  workflows::add_recipe(recipe_spec_gluon) %>% 
  parsnip::fit(birds)

model_tbl_submodels <- modeltime::modeltime_table(
  workflow_fit_rf_kfold,
  workflow_fit_glmnet,
  wflw_fit_nbeats_ensemble
)

# get predictions
all_preds <- model_tbl_submodels %>% 
  modeltime::modeltime_forecast(
    new_data    = future_tbl,
    actual_data = data_prepared_tbl,
    keep_data   = TRUE
  )

choose_model_2 <- choose_model %>% 
  dplyr::select(birds, better_model) %>% 
  dplyr::mutate(
    better_model = dplyr::case_when(
      better_model == "xgboost" ~ "XGBOOST",
      better_model == "lasso" ~ "GLMNET",
      better_model == "nbeats" ~ "NBEATS ENSEMBLE"
    )
  )

testing_df <- readr::read_csv("/Users/pascal/Downloads/birds_pred.csv") %>% 
  tidyr::separate(ID, c("date", "birds"), sep = ":") %>% 
  dplyr::mutate(date = lubridate::ym(date)) %>% 
  dplyr::select(-counts)
model_tbl_submodels_nbeats <- modeltime::modeltime_table(
  wflw_fit_nbeats_ensemble
)
all_preds_nbeats <- model_tbl_submodels_nbeats %>% 
  modeltime::modeltime_forecast(
    new_data    = testing_df,
    actual_data = birds,
    keep_data   = TRUE
  )
all_preds_below_5000 <- all_preds_nbeats %>% 
  dplyr::filter(
    .model_desc == "NBEATS ENSEMBLE"
  ) %>% 
  dplyr::select(.model_desc, .value, birds, date) %>% 
  dplyr::filter(!(birds %in% choose_model_2$birds))

all_preds_above_5000 <- all_preds %>% 
  dplyr::filter(
    .key != "actual"
  ) %>% 
  dplyr::select(.model_desc, .value, birds, date) %>% 
  dplyr::inner_join(
    choose_model_2, by = c(".model_desc" = "better_model", "birds")
  )

all_preds_below_5000 %>% 
  dplyr::bind_rows(
    all_preds_above_5000
  ) %>% 
  dplyr::mutate(
    date = as.character(date) %>% 
      stringr::str_sub(end = -4),
    ID = paste0(date, ":", birds)
  ) %>% 
  dplyr::select(ID, counts = .value) %>% 
  dplyr::mutate(
    counts = ifelse(counts < 0, 0, counts)
  ) -> temp
  
readr::read_csv("/Users/pascal/Downloads/birds_pred.csv")[, 1] %>% 
  dplyr::inner_join(temp, by = "ID") %>% 
  readr::write_csv("kaggle_1/data/birds_kaggle_preds.csv")

